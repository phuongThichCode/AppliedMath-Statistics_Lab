{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PROJECT: GRAM-SCHMIDT\n",
        "## Name: LÊ VÕ MINH PHƯƠNG\n",
        "## Student ID: 22120286\n",
        "## Subject: Toán Ứng dụng Thống kê\n",
        "## Class: 22_3"
      ],
      "metadata": {
        "id": "5d4jNuX9Zuk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#I. GRAM - SCHMIDT ALGORITHM FOR $QR$ DECOMPOSITION\n",
        "**$QR$ Decomposition using Gram - Scmidt algorithm**\n",
        "\n",
        "Given a matrix $ A $ of size $ m \\times n $ (where $ m \\geq n $), we want to decompose it into $ A = QR $, where $ Q $ is an orthogonal matrix of size $ m \\times n $ and $ R $ is an upper triangular matrix of size $ n \\times n $.\n",
        "\n",
        "1. **Initialize Matrices:**\n",
        "   - Initialize matrix $ Q $ of size $ m \\times n $ and matrix $ R $ of size $ n \\times n $ with zeros.\n",
        "\n",
        "2. **Iterate over Columns of $ A $:**\n",
        "   For each column $ k $ of $ A $, do the following steps 3 and 4:\n",
        "   \n",
        "3. **Compute $ k $-th Columns of $ Q $:**\n",
        "   - Extract the $ k $-th column of $ A $ and denote it as $ a_k $.\n",
        "   - Subtract the projection of $ a_k $ onto the already computed columns of $ Q $ from $ a_k $:  \n",
        "     $$ v_{k} = a_{k} - \\sum_{j=1}^{k-1} \\frac{q_j^T a_k}{||q_j||^2} q_j $$\n",
        "   - Normalize $ v_k $ to obtain the $ k $-th column of $ Q $:  \n",
        "     $$ q_{k} = \\frac{v_{k}}{||v_{k}||} $$\n",
        "\n",
        "4. **Compute Elements of $ R $:**\n",
        "   - Compute the diagonal elements of $ R $:\n",
        "   $$ R_{ii} = || v_i || $$\n",
        "   - Compute the off-diagonal elements of $ R $:  \n",
        "      $$R_ij = q_i^T . a_j $$\n",
        "\n",
        "5. **Repeat:**\n",
        "   - Repeat steps 3 and 4 for all columns of $ A $ until all columns have been processed.\n",
        "\n",
        "6. **Output:**\n",
        "   - The matrix $ Q $ contains the orthonormal columns of $ A $.\n",
        "   - The upper triangular matrix $ R $ contains the coefficients of the linear combinations of the columns of $ Q $ that reconstruct $ A $.\n"
      ],
      "metadata": {
        "id": "88B8ijlKRowL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Implement functions to perform QR decomposition"
      ],
      "metadata": {
        "id": "DjNB-HqNlj-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Check if a matrix is QR decomposition possible"
      ],
      "metadata": {
        "id": "3qpiUH5Jlti9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy # install numpy if haven't"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAbyYnaqlbYE",
        "outputId": "d219a596-4ee2-4a03-871b-b1a7272ca8f9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy #install scipy if haven't"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8FXZ7Giz0kr",
        "outputId": "4d77180f-0877-421d-eb1f-ccde3810cea1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dWUG9ilGZoRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77cb6678-1953-47e0-89ba-1af1c6a788cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QR decomposition is not possible: Matrix is not full rank (linearly dependent).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "#from scipy.linalg import qr\n",
        "\n",
        "def is_qr_possible(A):\n",
        "    A=np.array(A)\n",
        "    #Check if A is full rank\n",
        "    if np.linalg.matrix_rank(A) < min(A.shape):\n",
        "        print(\"QR decomposition is not possible: Matrix is not full rank (linearly dependent).\")\n",
        "        return False\n",
        "\n",
        "    print(\"QR decomposition is possible for input Matrix.\")\n",
        "    return True\n",
        "\n",
        "# Test with a matrix A\n",
        "A = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "result = is_qr_possible(A)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Write function to calculate the norm of a vector"
      ],
      "metadata": {
        "id": "Dy3EMY-zEBuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_Euclidean_norm (vector):\n",
        "  norm = 0\n",
        "  for i in vector:\n",
        "    norm += i*i\n",
        "  return norm**0.5\n"
      ],
      "metadata": {
        "id": "itI-Q5ywEbIi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Write function to round entries of a matrix"
      ],
      "metadata": {
        "id": "Vlm2cRKihnGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def round_matrix_entries(matrix:list, decimals:int):\n",
        "    for i in range(len(matrix)):\n",
        "        tmp=matrix[i]\n",
        "        for k in range(len(tmp)):\n",
        "            tmp[k]=round(tmp[k],decimals)\n",
        "        matrix[i]=tmp\n",
        "    return matrix"
      ],
      "metadata": {
        "id": "vdD3wVdnkODz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Write function to initialize matrix with all 0"
      ],
      "metadata": {
        "id": "m6sC8fgSlLrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zeros(m, n):# set 0 values for matrices Q and R\n",
        "    res = []\n",
        "    for i in range (m):\n",
        "      res.append ([0]*n)\n",
        "    return res"
      ],
      "metadata": {
        "id": "6kHN3AFRlSya"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Write function to perform QR decomposition"
      ],
      "metadata": {
        "id": "DhXz4WHiGG2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def qr_decomposition(A):\n",
        "\n",
        "    # Check if QR decomposition is possible at the beginning to avoid unnecessay step below\n",
        "    if not is_qr_possible(A):\n",
        "        return None, None\n",
        "\n",
        "    num_rows = len(A)\n",
        "    num_columns = len(A[0])\n",
        "    Q = zeros(num_rows, num_columns)\n",
        "    R = zeros(num_columns, num_columns)\n",
        "\n",
        "    for k in range(num_columns):\n",
        "        #construct the main diagonal\n",
        "        R[k][k] = calculate_Euclidean_norm([A[i][k] for i in range(num_rows)])\n",
        "\n",
        "        #check if A's columns linear dependent as their norm is 0 (on the diag of R matrix)\n",
        "        if R[k][k] < 1e-10:\n",
        "            raise ValueError(\"Column vectors are not linear independent!\")\n",
        "\n",
        "        else:\n",
        "            #calculate the entries for Q matrix\n",
        "            for i in range(num_rows):\n",
        "                Q[i][k] = A[i][k] / R[k][k] # R[k][k] is the norm of vectors\n",
        "\n",
        "        for j in range(k + 1, num_columns):\n",
        "            R[k][j] = sum(Q[i][k] * A[i][j] for i in range(num_rows))\n",
        "            for i in range(num_rows):\n",
        "                A[i][j] = A[i][j] - Q[i][k] * R[k][j]\n",
        "    return Q, R\n"
      ],
      "metadata": {
        "id": "OqwOmm4OYqA-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III. TEST THE PROGRAM AND USE BUILT-IN FUNCTION TO COMPARE THE RESULTS"
      ],
      "metadata": {
        "id": "P0MIvVeCbcMI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Test the program"
      ],
      "metadata": {
        "id": "grhNTcAalmMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Test with impossible QR decompositon matrix"
      ],
      "metadata": {
        "id": "wMSQo1T6jHl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "B = [[1, 2, 3], [2, 4, 6], [1, 3, 5]]\n",
        "\n",
        "Q, R = qr_decomposition(A)\n",
        "\n",
        "print(\"Q:\\n\",Q)\n",
        "print(\"R:\\n\", R)"
      ],
      "metadata": {
        "id": "XGCPmDr9YqHx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "990afcef-cb53-4db1-fc1b-7d52234ace32"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QR decomposition is not possible: Matrix is not full rank (linearly dependent).\n",
            "Q:\n",
            " None\n",
            "R:\n",
            " None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Test with possible QR decomposition matrices"
      ],
      "metadata": {
        "id": "3irFplkPjbzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = [[1, 1, 2], [2, -1, 1], [-2, 4, 1]]\n",
        "D = [[-1,-1,1], [1,3,3],[-1,-1,5],[1,3,7]]\n",
        "\n",
        "matrix_test = [[1,1,1], [2,2,0],[3,0,0],[0,0,1]]\n",
        "print ('Original matrix:\\n', np.array(matrix_test))\n",
        "\n",
        "Q, R = qr_decomposition(matrix_test)\n",
        "\n",
        "#round entries of matrix (if needed)\n",
        "#round_matrix_entries(Q,7)\n",
        "#round_matrix_entries(R,7)\n",
        "\n",
        "# convert to np.array for 'cleaner' format to display (not displaying commas as list)\n",
        "\n",
        "print(\"Q:\\n\",np.array(Q))\n",
        "print(\"R:\\n\", np.array(R))\n",
        "\n",
        "#multiply the resutl to check if the decomposition correct\n",
        "checkMatrix = np.array(Q) @ np.array (R)\n",
        "round_matrix_entries(checkMatrix,1)\n",
        "print (\"Check matrix:\\n\",checkMatrix)\n",
        "\n"
      ],
      "metadata": {
        "id": "8HFAMF1pjhaL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee6bbb2-67a9-4517-97cf-1d9fdcaf0cbf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original matrix:\n",
            " [[1 1 1]\n",
            " [2 2 0]\n",
            " [3 0 0]\n",
            " [0 0 1]]\n",
            "QR decomposition is possible for input Matrix.\n",
            "Q:\n",
            " [[ 2.67261242e-01  3.58568583e-01  5.96284794e-01]\n",
            " [ 5.34522484e-01  7.17137166e-01 -2.98142397e-01]\n",
            " [ 8.01783726e-01 -5.97614305e-01  2.06877846e-17]\n",
            " [ 0.00000000e+00  0.00000000e+00  7.45355992e-01]]\n",
            "R:\n",
            " [[3.74165739 1.33630621 0.26726124]\n",
            " [0.         1.79284291 0.35856858]\n",
            " [0.         0.         1.34164079]]\n",
            "Check matrix:\n",
            " [[ 1.  1.  1.]\n",
            " [ 2.  2.  0.]\n",
            " [ 3. -0.  0.]\n",
            " [ 0.  0.  1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Comment*: After multiplying the Q and R matrices, we get the original matrix."
      ],
      "metadata": {
        "id": "wQRvMNRtySbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Compare result with `numpy.linalg.qr()`, `scipy.linalg.qr()` and `torch.linalg.qr()` methods to compare the results"
      ],
      "metadata": {
        "id": "wK2GxsarlSLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Impossibly decompose"
      ],
      "metadata": {
        "id": "gU8uBrn8sK8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q_test, R_test = np.linalg.qr (B)\n",
        "\n",
        "print ('Q_numpy:\\n',Q_test,'\\n\\n','R_numpy:\\n',R_test)"
      ],
      "metadata": {
        "id": "3TBbO3disRAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0775ff30-a463-4386-c12e-1ac94ba5a981"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q_numpy:\n",
            " [[-4.08248290e-01 -1.82574186e-01 -8.94427191e-01]\n",
            " [-8.16496581e-01 -3.65148372e-01  4.47213595e-01]\n",
            " [-4.08248290e-01  9.12870929e-01  1.05471187e-15]] \n",
            "\n",
            " R_numpy:\n",
            " [[-2.44948974e+00 -5.30722778e+00 -8.16496581e+00]\n",
            " [ 0.00000000e+00  9.12870929e-01  1.82574186e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  1.55431223e-15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Comment*: Even if a matrix is not full rank (i.e., it has linearly dependent columns), `np.linalg.qr` can still return a $QR$ decomposition. This is because the function uses a numerical method that can handle small numerical errors and round-off issues that might make a matrix appear to be not full rank in a computer’s floating-point arithmetic. The resulting $Q$ and $R$ matrices might not be exactly orthogonal or upper triangular due to these numerical issues, but they will be close in the sense of numerical approximation."
      ],
      "metadata": {
        "id": "58fnJF2buHp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Possibly decompose"
      ],
      "metadata": {
        "id": "UU_IDeo9sSMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1 Use `numpy.linalg.qr()` and `scipy.linalg.qr()`"
      ],
      "metadata": {
        "id": "ormByXn1hmX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy as sp\n",
        "\n",
        "C = [[1, 1, 2], [2, -1, 1], [-2, 4, 1]]\n",
        "D = [[-1,-1,1], [1,3,3],[-1,-1,5],[1,3,7]]\n",
        "\n",
        "print (\"Original matrix:\\n\", np.array(C))\n",
        "Q, R = qr_decomposition(C)\n",
        "#round entries of matrix (if needed for a easier-to-see format)\n",
        "round_matrix_entries(Q,10)\n",
        "round_matrix_entries(R,10)\n",
        "\n",
        "# convert to np.array for 'cleaner' format to display (not displaying commas as list)\n",
        "\n",
        "print(\"Q:\\n\",np.array(Q))\n",
        "print(\"R:\\n\", np.array(R))\n",
        "\n",
        "#check by multiplying A=QR\n",
        "print (\"Check by Q@R:\")\n",
        "checkResult= np.array(Q) @ np.array(R)\n",
        "print (checkResult,'\\n')\n",
        "\n",
        "\n",
        "#-------------numpy--------------------\n",
        "print (\"The result of numpy method:\")\n",
        "C = [[1, 1, 2], [2, -1, 1], [-2, 4, 1]]\n",
        "D = [[-1,-1,1], [1,3,3],[-1,-1,5],[1,3,7]]\n",
        "Q_numpy, R_numpy = np.linalg.qr (np.array(C))\n",
        "\n",
        "#round entries in the matrices\n",
        "round_matrix_entries(Q_numpy,10)\n",
        "round_matrix_entries(R_numpy,10)\n",
        "print ('Q_numpy:\\n',Q_numpy,'\\n\\n','R_numpy:\\n',R_numpy)\n",
        "\n",
        "#-------------scipy--------------------\n",
        "print (\"\\nThe result of scipy method:\")\n",
        "Q_scipy, R_scipy = sp.linalg.qr (np.array(C))\n",
        "\n",
        "#round entries in the matrices\n",
        "round_matrix_entries(Q_scipy,10)\n",
        "round_matrix_entries(R_scipy,10)\n",
        "print ('Q_scipy:\\n',Q_scipy,'\\n\\n','R_scipy:\\n',R_scipy)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2HzfPgBEvQHJ",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e45b629e-3af0-4b64-e555-46eae92ac776"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original matrix:\n",
            " [[ 1  1  2]\n",
            " [ 2 -1  1]\n",
            " [-2  4  1]]\n",
            "QR decomposition is possible for input Matrix.\n",
            "Q:\n",
            " [[ 0.33333333  0.66666667  0.66666667]\n",
            " [ 0.66666667  0.33333333 -0.66666667]\n",
            " [-0.66666667  0.66666667 -0.33333333]]\n",
            "R:\n",
            " [[ 3.         -3.          0.66666667]\n",
            " [ 0.          3.          2.33333333]\n",
            " [ 0.          0.          0.33333333]]\n",
            "Check by Q@R:\n",
            "[[ 1.  1.  2.]\n",
            " [ 2. -1.  1.]\n",
            " [-2.  4.  1.]] \n",
            "\n",
            "The result of numpy method:\n",
            "Q_numpy:\n",
            " [[-0.33333333 -0.66666667  0.66666667]\n",
            " [-0.66666667 -0.33333333 -0.66666667]\n",
            " [ 0.66666667 -0.66666667 -0.33333333]] \n",
            "\n",
            " R_numpy:\n",
            " [[-3.          3.         -0.66666667]\n",
            " [ 0.         -3.         -2.33333333]\n",
            " [ 0.          0.          0.33333333]]\n",
            "\n",
            "The result of scipy method:\n",
            "Q_scipy:\n",
            " [[-0.33333333 -0.66666667  0.66666667]\n",
            " [-0.66666667 -0.33333333 -0.66666667]\n",
            " [ 0.66666667 -0.66666667 -0.33333333]] \n",
            "\n",
            " R_scipy:\n",
            " [[-3.          3.         -0.66666667]\n",
            " [ 0.         -3.         -2.33333333]\n",
            " [ 0.          0.          0.33333333]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Comment*: The sign minus $-$ in the Q and R matrices of two ways and my implementation are not identical but it is stills correct as $A$ is exactly equals to $Q R $ as there are multiple valid QR decompositions for a given matrix (check as below). Specifically, the sign of the columns of matrix $Q$ can be multiplied by any scalar, and the result will still be a valid orthogonal matrix. Similarly, the signs of the elements of matrix\n",
        "$R$ can be adjusted without affecting the validity of the $QR$ decomposition.\n",
        "The differences in sign are just a result of different conventions or implementation details."
      ],
      "metadata": {
        "id": "cG-6HxSZwIUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Original matrix:\\n\", np.array(C))\n",
        "print (\"\\nCheck result of numpy:\")\n",
        "check_numpy = Q_numpy@ R_numpy\n",
        "print (check_numpy)\n",
        "print (\"\\nCheck result of scipy:\")\n",
        "check_scipy = Q_scipy@ R_scipy\n",
        "print (check_scipy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2a0bK3M-cEH",
        "outputId": "7315e8ba-74cf-4aaa-b0a7-7eb16b97ae9c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original matrix:\n",
            " [[ 1  1  2]\n",
            " [ 2 -1  1]\n",
            " [-2  4  1]]\n",
            "\n",
            "Check result of numpy:\n",
            "[[ 1.  1.  2.]\n",
            " [ 2. -1.  1.]\n",
            " [-2.  4.  1.]]\n",
            "\n",
            "Check result of scipy:\n",
            "[[ 1.  1.  2.]\n",
            " [ 2. -1.  1.]\n",
            " [-2.  4.  1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.2 Use `torch.linalg.qr()` to compare"
      ],
      "metadata": {
        "id": "g6wFwEB9h42-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch #intall torch if it hasn't been installed"
      ],
      "metadata": {
        "id": "nb9t8-SHUwVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5f842a0-f9ad-46cf-8991-52d0a5bb2904"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E = [[-2,1,3], [1,0,0],[0,1,0], [0,0,1]]\n",
        "\n",
        "print (\"Original matrix:\\n\", np.array(E))\n",
        "Q, R = qr_decomposition(E)\n",
        "#round entries of matrix (if needed)\n",
        "#round_matrix_entries(Q,7)\n",
        "#round_matrix_entries(R,7)\n",
        "\n",
        "print(\"Q:\\n\",np.array(Q))\n",
        "print(\"R:\\n\", np.array(R))\n",
        "res = np.array(Q)@np.array(R)\n",
        "print (\"Check Q@R:\\n\")\n",
        "print(round_matrix_entries(res,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9KJdG0WsWmh",
        "outputId": "84b7d8c7-0213-4439-ed07-d52b528e312a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original matrix:\n",
            " [[-2  1  3]\n",
            " [ 1  0  0]\n",
            " [ 0  1  0]\n",
            " [ 0  0  1]]\n",
            "QR decomposition is possible for input Matrix.\n",
            "Q:\n",
            " [[-0.89442719  0.18257419  0.31622777]\n",
            " [ 0.4472136   0.36514837  0.63245553]\n",
            " [ 0.          0.91287093 -0.31622777]\n",
            " [ 0.          0.          0.63245553]]\n",
            "R:\n",
            " [[ 2.23606798 -0.89442719 -2.68328157]\n",
            " [ 0.          1.09544512  0.54772256]\n",
            " [ 0.          0.          1.58113883]]\n",
            "Check Q@R:\n",
            "\n",
            "[[-2.  1.  3.]\n",
            " [ 1. -0.  0.]\n",
            " [ 0.  1. -0.]\n",
            " [ 0.  0.  1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import tensor\n",
        "\n",
        "E = [[-2,1,3], [1,0,0],[0,1,0], [0,0,1]]\n",
        "E_tensor = torch.tensor(E, dtype=torch.float)\n",
        "\n",
        "# Perform QR decomposition\n",
        "Q_tensor, R_tensor = torch.linalg.qr(E_tensor)\n",
        "print ('Q_tensor: \\n', Q_tensor)\n",
        "print ('R_tensor: \\n', R_tensor)\n",
        "\n",
        "check_tensor=Q_tensor@R_tensor\n",
        "print (\"Check tensor:\\n\", check_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj-YWb-sUS_p",
        "outputId": "51ab8f65-5ef4-469a-af86-17e968dec1e3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q_tensor: \n",
            " tensor([[-0.8944, -0.1826,  0.3162],\n",
            "        [ 0.4472, -0.3651,  0.6325],\n",
            "        [ 0.0000, -0.9129, -0.3162],\n",
            "        [ 0.0000, -0.0000,  0.6325]])\n",
            "R_tensor: \n",
            " tensor([[ 2.2361, -0.8944, -2.6833],\n",
            "        [ 0.0000, -1.0954, -0.5477],\n",
            "        [ 0.0000,  0.0000,  1.5811]])\n",
            "Check tensor:\n",
            " tensor([[-2.0000e+00,  1.0000e+00,  3.0000e+00],\n",
            "        [ 1.0000e+00,  8.9407e-08,  2.6879e-07],\n",
            "        [ 0.0000e+00,  1.0000e+00,  4.4419e-08],\n",
            "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Comment:* The difference in the $Q$ and $R$ matrices between my implementation and `np.linalg.qr()`, `sp.linalg.qr()` and `torch.linalg.qr()` likely arises from the fact that they use a different algorithm or implementation details that may result in different numerical precision or handling of certain cases, the result from `torch.linalg.qr()` seems to have result different from other methods as it's automatically rounded to 4 digits after comma. However, after checking by multiplying $QR$, we always get the original matrix.\n"
      ],
      "metadata": {
        "id": "pKIXptwjq9DA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IV. APPLICATIONS OF QR DECOMPOSITION"
      ],
      "metadata": {
        "id": "WYoHWFF6P88z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Compute Inverse Matrix:\n",
        "To compute the inverse of a matrix $A$ using its QR decomposition, we use the formula:\n",
        "\n",
        "$$ A^{-1} = R^{-1} Q^T $$\n",
        "\n",
        "Where:\n",
        "- $A$ is the original matrix.\n",
        "- $Q$ is the orthogonal matrix from the QR decomposition of $A$.\n",
        "- $R$ is the upper triangular matrix from the QR decomposition of $A$.\n",
        "- $R^{-1}$ is the inverse of the upper triangular matrix $R$.\n",
        "- $Q^T$ is the transpose of the orthogonal matrix $Q$.  \n",
        "\n",
        "## 2. Solving Linear Least Squares Problems\n",
        "QR decomposition is used to solve linear least squares problems efficiently. Here's how it's done:\n",
        "\n",
        "- Given a linear system $Ax = b$ where $A$ is an $m \\times n$ matrix (with $m \\geq n$), $x$ is an $n \\times 1$ vector of unknowns, and $b$ is an $m \\times 1$ vector of constants.\n",
        "\n",
        "-  If the system $Ax = b$ is overdetermined (i.e., there are more equations than unknowns), there may not be an exact solution. In such cases, we seek the \"best\" solution in terms of minimizing the sum of squared residuals, which leads to the least squares problem.\n",
        "\n",
        "- To solve the least squares problem, we first perform QR decomposition on matrix $A$ to obtain $A = QR$, where $Q$ is an $m \\times n$ orthogonal matrix and $R$ is an $n \\times n$ upper triangular matrix.\n",
        "\n",
        "- We can then rewrite the original system as $Rx = Q^Tb$. Since $R$ is upper triangular, this system can be efficiently solved using back substitution.\n",
        "\n",
        "- After obtaining the solution $x$, we have the best-fit solution to the least squares problem.\n",
        "\n",
        "By using QR decomposition, we transform the original linear least squares problem into an equivalent problem with a triangular matrix, making it computationally efficient to solve.\n",
        "\n",
        "## 3. Image compression:\n",
        "QR decomposition can be utilized in image compression techniques to reduce the size of an image while preserving its essential features. By representing the image matrix as a product of an orthogonal matrix $Q$ and an upper triangular matrix $R$, the original image can be approximated with fewer coefficients. This reduction in data size can lead to more efficient storage and transmission of images.\n"
      ],
      "metadata": {
        "id": "gwWTyuWMkMWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V. FUNCTIONS' DESCRIPTION\n",
        "- `is_qr_possible(A)`: check at first if the given A matrix possible for $QR$ decomposition on the cases when the vector are not linearly independent.\n",
        "- `calculate_Euclidean_norm (vector)`: return the Euclidean norm of a vector.\n",
        "- `round_matrix_entries(matrix:list, decimals:int)`: used to round all entries of a matrix with `decimals` digits after comma.\n",
        "- `zeros(m, n)`: initialize the $0$ matrix for $Q$ and $R$  matrices.\n",
        "- `qr_decomposition(A)`: the main function to perform $QR$ decomposition, return the $Q$ and $R$ matrices (if possible) or return None (if impossible). The implementation uses exactly Gram - Schmidt algorithm presented above."
      ],
      "metadata": {
        "id": "hJfCZKkWqkfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ This \\space is \\space the \\space end \\space of \\space the \\space Project. $$"
      ],
      "metadata": {
        "id": "t2GAFiYSzjY1"
      }
    }
  ]
}